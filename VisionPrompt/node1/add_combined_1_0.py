'''20step/9min
This file is used to add objects to images and save both with textbox (bounding box + label) and without textbox (text only)
Creates two folder structures:
- with_textbox: input (original with bbox), output (edited)
- wo_textbox: input (original with text only), output (edited)
'''
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"
import random
import json
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
from prompt_utils import polish_edit_prompt, edit_api
import glob
from tqdm import tqdm
import re

from multi3_infer_plus import MyQwenImageEditPipeline, MultiGPUTransformer


class ObjectPromptGenerator:
    """ç‰©ä½“ç”Ÿæˆpromptçš„ç±»,å‚è€ƒadd_text_boxes_to_images.pyçš„generate_unique_textå‡½æ•°"""
    
    def __init__(self):
        self.used_texts = set()  # è®°å½•å·²ä½¿ç”¨çš„æ–‡æœ¬,ç¡®ä¿å”¯ä¸€æ€§
        
        # ä»JSONæ–‡ä»¶åŠ è½½ç‰©ä½“è¯åº“
        self.objects = self._load_objects_from_json()
        
        # é¢œè‰²åˆ—è¡¨ - ç®€åŒ–ä¸ºçŸ­è¯æ±‡,é¿å…æ–‡æœ¬è¿‡é•¿
        self.colors = [
            # åŸºç¡€é¢œè‰²
            "red", "blue", "green", "yellow", "orange", "purple", "pink", "brown",
            "black", "white", "gray", "silver", "gold",
            
            # æ‰©å±•é¢œè‰² - åªä¿ç•™çŸ­è¯æ±‡
            "cyan", "lime", "navy", "olive", "teal", "aqua", "coral", "violet", 
            "tan", "cream", "ivory", "bronze", "copper",
                        
            # ç‰¹æ®Šè‰²è°ƒ
            "metallic", "glossy", "matte", "neon", "fluorescent", "pastel", "vintage",
            "rainbow", "multicolored", "transparent", "crystal", "frosted"
        ]
        
        # ä½ç½®æè¿°è¯ - ç®€åŒ–ä¸ºçŸ­è¯æ±‡,é¿å…æ–‡æœ¬è¿‡é•¿
        self.positions = [
            # åŸºç¡€ä½ç½®
            "here", "there",
                        
            # ç®€åŒ–çš„ç©ºé—´ä½ç½®
            "nearby",
            
            # ç›¸å¯¹æ–¹å‘
            "close by", "nearby", "somewhere",
            
            # ç®€å•ä½ç½®
            "", "in position", "in place"
        ]
        
        # åŠ¨ä½œç±»å‹ - åªä¿ç•™æ·»åŠ ç‰©ä½“
        self.action_types = ["add"]
    
    def _load_objects_from_json(self):
        """ä»JSONæ–‡ä»¶åŠ è½½ç‰©ä½“è¯åº“"""
        json_file = "/storage/v-jinpewang/lab_folder/junchao/data/objects.json"
        
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    objects = json.load(f)
                
                if isinstance(objects, list) and objects:
                    # è¿‡æ»¤æ‰è¿‡é•¿çš„ç‰©ä½“åç§°,ä¿æŒæ–‡æœ¬ç®€æ´
                    filtered_objects = [obj for obj in objects if len(obj) <= 15]
                    print(f"âœ… æˆåŠŸåŠ è½½ç‰©ä½“è¯åº“: {json_file} ({len(filtered_objects)} ä¸ªç‰©ä½“,å·²è¿‡æ»¤é•¿åç§°)")
                    return filtered_objects
                else:
                    print(f"âŒ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {json_file}")
                    
            except json.JSONDecodeError:
                print(f"âŒ JSONæ–‡ä»¶è§£æé”™è¯¯: {json_file}")
            except Exception as e:
                print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {json_file} - {e}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°ç‰©ä½“è¯åº“æ–‡ä»¶: {json_file}")
    
    def generate_unique_object_prompt(self, max_length: int = 25):
        """ç”Ÿæˆå”¯ä¸€çš„ç‰©ä½“æ·»åŠ prompt,è¿”å›(prompt, object_name)"""
        max_attempts = 1000
        attempts = 0
        
        while attempts < max_attempts:
            obj1 = random.choice(self.objects)
            color = random.choice(self.colors)
            
            # åŸºç¡€åŠ¨è¯ï¼ˆé«˜é¢‘ï¼‰
            base_verbs = ["add", "put", "place", "draw", "create", "insert"]
            
            # æ„å»ºä¸åŒå¤æ‚åº¦çš„æ¨¡æ¿ç»„
            simple_templates = []  # ç®€å•æ¨¡æ¿ï¼ˆé«˜é¢‘ï¼‰
            medium_templates = []  # ä¸­ç­‰æ¨¡æ¿ï¼ˆä¸­é¢‘ï¼‰
            
            # ç®€å•æ¨¡æ¿ï¼šåŠ¨è¯ + ç‰©ä½“ï¼ˆ70%æ¦‚ç‡ï¼‰
            for verb in base_verbs:
                simple_templates.append(f"{verb} a {obj1}")
            
            # ä¸­ç­‰æ¨¡æ¿ï¼šåŠ¨è¯ + é¢œè‰² + ç‰©ä½“ï¼ˆ30%æ¦‚ç‡ï¼‰
            for verb in base_verbs:
                medium_templates.append(f"{verb} a {color} {obj1}")
            
            # æŒ‰æƒé‡éšæœºé€‰æ‹©æ¨¡æ¿ç±»å‹
            template_choice = random.random()
            if template_choice < 0.7:  # 70%é€‰æ‹©ç®€å•æ¨¡æ¿
                templates = simple_templates
            else:  # 30%é€‰æ‹©ä¸­ç­‰æ¨¡æ¿
                templates = medium_templates
            
            # ä»é€‰å®šçš„æ¨¡æ¿ç»„ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿
            if templates:
                template = random.choice(templates)
                # æ¸…ç†å¤šä½™ç©ºæ ¼
                text = ' '.join(template.split())
                
                # æ£€æŸ¥é•¿åº¦é™åˆ¶å’Œå”¯ä¸€æ€§
                if len(text) <= max_length and text not in self.used_texts:
                    self.used_texts.add(text)
                    return text, obj1  # è¿”å›promptå’Œç‰©ä½“åç§°
            
            attempts += 1
        
        # å¦‚æœç”Ÿæˆäº†å¤ªå¤šé‡å¤,ä½¿ç”¨æœ€çŸ­çš„æ¨¡æ¿
        obj1 = random.choice(self.objects)
        fallback_text = f"add {obj1}"
        if len(fallback_text) > max_length:
            # å¦‚æœç‰©ä½“åç§°å¤ªé•¿,æˆªæ–­
            fallback_text = f"add {obj1[:max_length-4]}"
        
        unique_text = f"{fallback_text}#{random.randint(10, 99)}"
        self.used_texts.add(unique_text)
        return unique_text, obj1  # è¿”å›promptå’Œç‰©ä½“åç§°


class TextBoxDrawer:
    """æ–‡æœ¬æ¡†ç»˜åˆ¶ç±»,å‚è€ƒadd_text_boxes_to_images.py"""
    
    def __init__(self):
        pass
    
    def get_average_color(self, image, x: int, y: int, width: int, height: int):
        """è·å–æŒ‡å®šåŒºåŸŸçš„å¹³å‡é¢œè‰²"""
        img_array = np.array(image) if isinstance(image, Image.Image) else image
        img_height, img_width = img_array.shape[:2]
        
        # ç®€åŒ–çš„è¾¹ç•Œæ£€æŸ¥å’Œé‡‡æ ·
        x = max(10, min(x, img_width - width - 10))
        y = max(10, min(y, img_height - height - 10))
        x_end = min(x + width, img_width - 10)
        y_end = min(y + height, img_height - 10)
        
        # ç›´æ¥é‡‡æ ·ä¸­å¿ƒåŒºåŸŸ
        center_x = (x + x_end) // 2
        center_y = (y + y_end) // 2
        sample_size = min(20, width // 3, height // 3)
        
        region = img_array[center_y:center_y+sample_size, center_x:center_x+sample_size]
        
        if len(region.shape) == 3:
            avg_color = np.mean(region, axis=(0, 1))
            return tuple(int(c) for c in avg_color)
        else:
            avg_color = int(np.mean(region))
            return (avg_color, avg_color, avg_color)
    
    def get_contrasting_color(self, background_color):
        """æ ¹æ®èƒŒæ™¯è‰²é€‰æ‹©å¯¹æ¯”åº¦æœ€é«˜çš„å­—ä½“é¢œè‰²"""
        # ç®€åŒ–çš„å€™é€‰é¢œè‰²
        colors = [(0, 0, 0), (255, 255, 255), (255, 255, 0), (255, 0, 255), 
                 (0, 255, 255), (255, 100, 0), (0, 255, 0), (255, 0, 0)]
        
        # ç®€åŒ–çš„äº®åº¦è®¡ç®—å’Œå¯¹æ¯”åº¦é€‰æ‹©
        bg_luminance = 0.299 * background_color[0] + 0.587 * background_color[1] + 0.114 * background_color[2]
        
        best_color = (0, 0, 0)
        max_contrast = 0
        
        for color in colors:
            luminance = 0.299 * color[0] + 0.587 * color[1] + 0.114 * color[2]
            contrast = abs(bg_luminance - luminance)
            if contrast > max_contrast:
                max_contrast = contrast
                best_color = color
        
        return best_color
    
    def _load_font(self, size: int):
        """åŠ è½½å­—ä½“çš„ç»Ÿä¸€æ–¹æ³•"""
        # å°è¯•åŠ è½½Times New Romanå­—ä½“
        font_paths = [
            "/storage/v-jinpewang/lab_folder/junchao/data/Times_New_Roman.ttf",
            "Times New Roman.ttf"
        ]
        
        for font_path in font_paths:
            try:
                return ImageFont.truetype(font_path, size)
            except:
                continue
        
        # å¦‚æœéƒ½å¤±è´¥,ä½¿ç”¨é»˜è®¤å­—ä½“
        return ImageFont.load_default()
    
    def adjust_font_size_with_actual_measurement(self, text: str, img_width: int, img_height: int, 
                                               initial_size: int = 32, min_size: int = 8):
        """ä½¿ç”¨å®é™…å­—ä½“æµ‹é‡åŠ¨æ€è°ƒæ•´å­—ä½“å¤§å°"""
        # åˆ›å»ºä¸´æ—¶å›¾åƒç”¨äºæµ‹é‡
        temp_img = Image.new('RGB', (100, 100))
        temp_draw = ImageDraw.Draw(temp_img)
        
        # è®¡ç®—å¯ç”¨ç©ºé—´,é¢„ç•™å®‰å…¨è¾¹è·
        safety_margin = 40
        max_available_width = img_width - safety_margin
        max_available_height = img_height - safety_margin
        
        # å¦‚æœå›¾ç‰‡å¤ªå°,è¿›ä¸€æ­¥å‡å°‘å®‰å…¨è¾¹è·
        if max_available_width < 100 or max_available_height < 50:
            safety_margin = 20
            max_available_width = img_width - safety_margin
            max_available_height = img_height - safety_margin
        
        # æ ¹æ®æ–‡æœ¬é•¿åº¦åŠ¨æ€è°ƒæ•´åˆå§‹å­—ä½“å¤§å°
        text_length = len(text)
        
        if text_length <= 8:  # çŸ­æ–‡æœ¬ - å¤§å­—ä½“
            dynamic_initial_size = min(48, initial_size + 16)
            dynamic_min_size = max(16, min_size + 8)
        elif text_length <= 15:  # ä¸­ç­‰æ–‡æœ¬ - æ ‡å‡†å­—ä½“
            dynamic_initial_size = initial_size
            dynamic_min_size = min_size + 4
        elif text_length <= 25:  # è¾ƒé•¿æ–‡æœ¬ - å°å­—ä½“
            dynamic_initial_size = max(24, initial_size - 8)
            dynamic_min_size = min_size + 2
        else:  # å¾ˆé•¿æ–‡æœ¬ - æœ€å°å­—ä½“
            dynamic_initial_size = max(16, initial_size - 16)
            dynamic_min_size = min_size
        
        # è¿›ä¸€æ­¥æ ¹æ®å›¾ç‰‡å¤§å°è°ƒæ•´å­—ä½“èŒƒå›´
        img_area = img_width * img_height
        if img_area < 200000:  # å°å›¾ç‰‡
            dynamic_initial_size = int(dynamic_initial_size * 0.8)
            dynamic_min_size = max(6, int(dynamic_min_size * 0.8))
        elif img_area > 1000000:  # å¤§å›¾ç‰‡
            dynamic_initial_size = int(dynamic_initial_size * 1.2)
            dynamic_min_size = int(dynamic_min_size * 1.1)
        
        # ç¡®ä¿å­—ä½“å¤§å°åœ¨åˆç†èŒƒå›´å†…
        dynamic_initial_size = max(dynamic_min_size, min(64, dynamic_initial_size))
        
        for font_size in range(dynamic_initial_size, dynamic_min_size - 1, -1):
            # åŠ è½½å­—ä½“
            font = self._load_font(font_size)
            
            # å®é™…æµ‹é‡æ–‡æœ¬å°ºå¯¸ï¼Œä½¿ç”¨ç²¾ç¡®çš„è¾¹ç•Œæ¡†
            bbox = temp_draw.textbbox((0, 0), text, font=font)
            actual_text_width = bbox[2] - bbox[0]
            actual_text_height = bbox[3] - bbox[1]
            
            # åŠ¨æ€è°ƒæ•´padding,æ ¹æ®å­—ä½“å¤§å°å’Œæ–‡æœ¬é•¿åº¦
            if font_size <= 12:
                padding = max(8, font_size // 2)  # å¢åŠ æœ€å°paddingç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´
            elif font_size <= 20:
                padding = max(10, font_size // 2)
            else:
                padding = max(12, font_size // 3)
            
            # é•¿æ–‡æœ¬ä½¿ç”¨æ›´å°‘çš„paddingä»¥èŠ‚çœç©ºé—´ï¼Œä½†ä¿æŒæœ€å°å€¼
            if text_length > 20:
                padding = max(6, padding - 2)
            
            # ä¸ºäº†ç¡®ä¿æ–‡æœ¬å®Œå…¨å±…ä¸­ï¼Œç»™é«˜åº¦é¢å¤–å¢åŠ ä¸€äº›ç©ºé—´
            # è¿™æ˜¯å› ä¸ºæŸäº›å­—ä½“çš„ascent/descentå¯èƒ½ä¸å¯¹ç§°
            extra_height_margin = max(2, font_size // 8)
            
            box_width = actual_text_width + 2 * padding
            box_height = actual_text_height + 2 * padding + extra_height_margin
            
            # ä¸¥æ ¼æ£€æŸ¥æ–‡æœ¬æ¡†æ˜¯å¦èƒ½å®Œå…¨æ”¾å…¥å›¾ç‰‡
            if box_width <= max_available_width and box_height <= max_available_height:
                return font_size, box_width, box_height, actual_text_width, actual_text_height, font, padding
        
        # å¦‚æœæ‰€æœ‰å­—ä½“éƒ½å¤ªå¤§,ä½¿ç”¨æœ€å°å­—ä½“å¹¶å¼ºåˆ¶é€‚åº”
        font = self._load_font(dynamic_min_size)
        bbox = temp_draw.textbbox((0, 0), text, font=font)
        actual_text_width = bbox[2] - bbox[0]
        actual_text_height = bbox[3] - bbox[1]
        
        # æœ€å°paddingï¼Œä½†è¦ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ç”¨äºå±…ä¸­
        min_padding = max(4, dynamic_min_size // 4)
        extra_height_margin = max(2, dynamic_min_size // 8)
        
        forced_box_width = min(actual_text_width + 2 * min_padding, max_available_width)
        forced_box_height = min(actual_text_height + 2 * min_padding + extra_height_margin, max_available_height)
        
        return dynamic_min_size, forced_box_width, forced_box_height, actual_text_width, actual_text_height, font, min_padding
    

    def draw_bounding_box_with_text(self, image: Image.Image, x1: int, y1: int, x2: int, y2: int, text: str):
        """ç»˜åˆ¶è¾¹ç•Œæ¡†å¹¶æ·»åŠ æ–‡å­—æ ‡ç­¾"""
        # åœ¨æ¡†çš„å‘¨è¾¹åŠ¨æ€è¯†åˆ«ä½ç½®æ¥å†™æ–‡å­—!!!

        img_copy = image.copy()
        
        # ç¡®ä¿åæ ‡åœ¨å›¾ç‰‡èŒƒå›´å†…
        x1 = max(0, min(x1, image.width - 1))
        y1 = max(0, min(y1, image.height - 1))
        x2 = max(x1 + 1, min(x2, image.width))
        y2 = max(y1 + 1, min(y2, image.height))
        
        # åˆ›å»ºå¸¦é€æ˜åº¦çš„è¦†ç›–å±‚
        overlay = Image.new('RGBA', img_copy.size, (255, 255, 255, 0))
        overlay_draw = ImageDraw.Draw(overlay)
        
        # ç»˜åˆ¶ç‰©ä½“è¾¹æ¡†ï¼ˆçº¢è‰²è¾¹æ¡†ï¼Œç›´æ¥ä½¿ç”¨è¾¹ç•Œæ¡†åæ ‡ï¼‰
        border_color = (255, 0, 0, 255)
        overlay_draw.rectangle([x1, y1, x2, y2], fill=None, outline=border_color, width=3)
        
        # æ·»åŠ æ–‡å­—æ ‡ç­¾
        if text:
            # è®¡ç®—åˆé€‚çš„å­—ä½“å¤§å°ï¼ˆåŸºäºå›¾ç‰‡å°ºå¯¸ï¼Œè®©æ–‡å­—æ›´å¤§ï¼‰
            min_font_size = 28  # æé«˜æœ€å°å­—ä½“å¤§å°
            base_font_size = max(min_font_size, min(image.width, image.height) // 20)  # è°ƒæ•´æ¯”ä¾‹è®©å­—ä½“æ›´å¤§
            
            try:
                # ä½¿ç”¨æŒ‡å®šçš„å­—ä½“æ–‡ä»¶
                from PIL import ImageFont
                try:
                    # ä½¿ç”¨æŒ‡å®šçš„Times New Romanå­—ä½“
                    font = ImageFont.truetype("/storage/v-jinpewang/lab_folder/junchao/data/Times_New_Roman.ttf", base_font_size)
                    print(f"æˆåŠŸåŠ è½½æŒ‡å®šå­—ä½“: Times_New_Roman.ttfï¼Œå¤§å°: {base_font_size}")
                except (OSError, IOError) as e:
                    print(f"âŒ æ— æ³•åŠ è½½æŒ‡å®šå­—ä½“æ–‡ä»¶: {e}")
                    try:
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“
                        font = ImageFont.truetype("arial.ttf", base_font_size)
                        print("ä½¿ç”¨å¤‡ç”¨å­—ä½“: arial.ttf")
                    except (OSError, IOError):
                        try:
                            font = ImageFont.truetype("DejaVuSans.ttf", base_font_size)
                            print("ä½¿ç”¨å¤‡ç”¨å­—ä½“: DejaVuSans.ttf")
                        except (OSError, IOError):
                            # ä½¿ç”¨PILé»˜è®¤å­—ä½“
                            font = ImageFont.load_default()
                            print("ä½¿ç”¨PILé»˜è®¤å­—ä½“")
            except ImportError:
                # å¦‚æœImageFontä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
                font = None
                print("ImageFontä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            
            # è·å–æ–‡å­—å°ºå¯¸
            if font:
                bbox = overlay_draw.textbbox((0, 0), text, font=font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
            else:
                # ä½¿ç”¨é»˜è®¤å­—ä½“æ—¶çš„ä¼°ç®—
                text_width = len(text) * (base_font_size // 2)
                text_height = base_font_size
            
            # ç¡®å®šæ–‡å­—ä½ç½®ï¼šæ ¹æ®è¾¹ç•Œæ¡†ä½ç½®æ™ºèƒ½é€‰æ‹©
            margin = 5  # æ–‡å­—ä¸è¾¹ç•Œæ¡†çš„é—´è·
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦é è¿‘å›¾ç‰‡é¡¶éƒ¨æˆ–åº•éƒ¨
            near_top = y1 < text_height + margin + 20  # å¦‚æœè¾¹ç•Œæ¡†é¡¶éƒ¨è·ç¦»å›¾ç‰‡é¡¶éƒ¨å¤ªè¿‘
            near_bottom = y2 > image.height - text_height - margin - 20  # å¦‚æœè¾¹ç•Œæ¡†åº•éƒ¨è·ç¦»å›¾ç‰‡åº•éƒ¨å¤ªè¿‘
            
            # è®¡ç®—æ¡†çš„ä¸­å¿ƒå’Œå®½åº¦
            box_center_x = (x1 + x2) // 2
            box_width = x2 - x1
            
            # å…ˆç¡®å®šå‚ç›´ä½ç½®ï¼ˆä¸Šæ–¹ã€ä¸‹æ–¹æˆ–å†…éƒ¨ï¼‰
            if near_top and not near_bottom:
                # è¾¹ç•Œæ¡†é è¿‘é¡¶éƒ¨ï¼Œæ–‡å­—æ”¾åœ¨è¾¹ç•Œæ¡†ä¸‹æ–¹
                text_y = y2 + margin
                position_desc = "è¾¹ç•Œæ¡†ä¸‹æ–¹"
            elif near_bottom and not near_top:
                # è¾¹ç•Œæ¡†é è¿‘åº•éƒ¨ï¼Œæ–‡å­—æ”¾åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹
                text_y = y1 - text_height - margin
                position_desc = "è¾¹ç•Œæ¡†ä¸Šæ–¹"
            elif near_top and near_bottom:
                # è¾¹ç•Œæ¡†å æ®äº†å¤§éƒ¨åˆ†å‚ç›´ç©ºé—´ï¼Œæ–‡å­—æ”¾åœ¨è¾¹ç•Œæ¡†å†…éƒ¨é¡¶éƒ¨
                text_y = y1 + margin
                position_desc = "è¾¹ç•Œæ¡†å†…éƒ¨é¡¶éƒ¨"
            else:
                # é»˜è®¤æƒ…å†µï¼šæ–‡å­—æ”¾åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹
                text_y = y1 - text_height - margin
                position_desc = "è¾¹ç•Œæ¡†ä¸Šæ–¹ï¼ˆé»˜è®¤ï¼‰"
            
            # è®¡ç®—æ°´å¹³ä½ç½®ï¼šå°è¯•è®©æ–‡æœ¬å±…ä¸­å¯¹é½æ¡†ï¼Œæˆ–è€…æ ¹æ®ç©ºé—´æ™ºèƒ½è°ƒæ•´
            # é¦–é€‰ï¼šæ–‡æœ¬ä¸­å¿ƒå¯¹é½æ¡†ä¸­å¿ƒ
            text_x = box_center_x - text_width // 2
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå·¦è¾¹ç•Œ
            if text_x < 0:
                text_x = 0  # è´´è¿‘å·¦è¾¹ç•Œ
                adjustment = "å·¦è¾¹ç•Œå¯¹é½"
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå³è¾¹ç•Œ
            elif text_x + text_width > image.width:
                text_x = image.width - text_width  # è´´è¿‘å³è¾¹ç•Œ
                adjustment = "å³è¾¹ç•Œå¯¹é½"
            else:
                adjustment = "å±…ä¸­å¯¹é½æ¡†"
            
            # è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šå¦‚æœæ–‡æœ¬è·ç¦»æ¡†å¤ªè¿œï¼Œé€‚å½“è°ƒæ•´ä½ç½®ä½¿å…¶é è¿‘æ¡†
            # å®šä¹‰"å¤ªè¿œ"çš„é˜ˆå€¼ï¼šæ–‡æœ¬ä¸æ¡†ä¹‹é—´çš„è·ç¦»è¶…è¿‡æ¡†å®½çš„ä¸€åŠ
            max_distance = box_width * 0.5
            
            # å¦‚æœæ–‡æœ¬å®Œå…¨åœ¨æ¡†çš„å·¦ä¾§ä¸”è·ç¦»å¤ªè¿œï¼Œå³ç§»é è¿‘æ¡†
            if text_x + text_width < x1 and (x1 - (text_x + text_width)) > max_distance:
                text_x = max(0, x1 - text_width - 10)  # é è¿‘æ¡†å·¦è¾¹ï¼Œç•™10åƒç´ é—´è·
                adjustment = "å·¦ç§»é è¿‘æ¡†"
            # å¦‚æœæ–‡æœ¬å®Œå…¨åœ¨æ¡†çš„å³ä¾§ä¸”è·ç¦»å¤ªè¿œï¼Œå·¦ç§»é è¿‘æ¡†
            elif text_x > x2 and (text_x - x2) > max_distance:
                text_x = min(image.width - text_width, x2 + 10)  # é è¿‘æ¡†å³è¾¹ï¼Œç•™10åƒç´ é—´è·
                adjustment = "å³ç§»é è¿‘æ¡†"
            
            # æœ€ç»ˆè¾¹ç•Œæ£€æŸ¥ï¼Œç¡®ä¿ä¸è¶…å‡ºå›¾ç‰‡
            text_x = max(0, min(text_x, image.width - text_width))
            text_y = max(0, min(text_y, image.height - text_height))
            
            print(f"æ–‡å­—ä½ç½®ï¼š{position_desc}ï¼Œæ°´å¹³è°ƒæ•´ï¼š{adjustment} ({text_x}, {text_y})")
            
            # è®¡ç®—æ–‡å­—èƒŒæ™¯åŒºåŸŸ
            bg_padding = 3
            bg_x1 = max(0, text_x - bg_padding)
            bg_y1 = max(0, text_y - bg_padding)
            bg_x2 = min(image.width, text_x + text_width + bg_padding)
            bg_y2 = min(image.height, text_y + text_height + bg_padding)
            bg_width = bg_x2 - bg_x1
            bg_height = bg_y2 - bg_y1
            
            # æ£€æµ‹èƒŒæ™¯è‰²å¹¶é€‰æ‹©å¯¹æ¯”è‰²
            background_color = self.get_average_color(image, bg_x1, bg_y1, bg_width, bg_height)
            text_color_rgb = self.get_contrasting_color(background_color)
            text_color_rgba = (*text_color_rgb, 255)
            
            print(f"èƒŒæ™¯é¢œè‰²: {background_color}, é€‰æ‹©çš„æ–‡å­—é¢œè‰²: {text_color_rgb}")
            
            # æ ¹æ®æ–‡å­—é¢œè‰²é€‰æ‹©æè¾¹é¢œè‰²
            outline_color = (0, 0, 0, 255) if text_color_rgb != (0, 0, 0) else (255, 255, 255, 255)
            
            # æ ¹æ®å­—ä½“å¤§å°è°ƒæ•´æè¾¹æ•ˆæœ
            if base_font_size < 16:
                outline_width = 1
                # åªç»˜åˆ¶4ä¸ªæ–¹å‘çš„æè¾¹,å‡å°‘ç²˜è¿
                outline_positions = [(-1, 0), (1, 0), (0, -1), (0, 1)]
            else:
                outline_width = 2
                # å¤§å­—ä½“ä½¿ç”¨8æ–¹å‘æè¾¹
                outline_positions = [(-outline_width, -outline_width), (-outline_width, 0), (-outline_width, outline_width),
                                   (0, -outline_width), (0, outline_width),
                                   (outline_width, -outline_width), (outline_width, 0), (outline_width, outline_width)]
            
            # ç»˜åˆ¶æè¾¹
            for dx, dy in outline_positions:
                overlay_draw.text((text_x + dx, text_y + dy), text, 
                                fill=outline_color, font=font)
            
            # ç»˜åˆ¶ä¸»æ–‡å­—ï¼ˆä½¿ç”¨åŠ¨æ€é€‰æ‹©çš„é¢œè‰²ï¼‰
            overlay_draw.text((text_x, text_y), text, fill=text_color_rgba, font=font)
            
            print(f"ç»˜åˆ¶æ–‡å­—: '{text}' åœ¨ä½ç½® ({text_x}, {text_y}), å­—ä½“å¤§å°: {base_font_size}")
        
        # åˆå¹¶å›¾åƒ
        img_copy = Image.alpha_composite(img_copy.convert('RGBA'), overlay).convert('RGB')
        
        print(f"ç»˜åˆ¶è¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
        
        return img_copy, {
            'bounding_box': (x1, y1, x2, y2),
            'text': text,
            'text_position': (text_x, text_y) if text else None,
            'background_color': background_color if text else None,
            'text_color': text_color_rgb if text else None,
            'font_size': base_font_size if text else None
        }
    
    def draw_text_only_at_center(self, image: Image.Image, text: str, center_x: int, center_y: int):
        """åœ¨æŒ‡å®šä¸­å¿ƒä½ç½®åªç»˜åˆ¶æ–‡æœ¬ï¼ˆæ— è¾¹æ¡†ï¼‰- ä½¿ç”¨ä¸draw_text_box_at_centerå®Œå…¨ç›¸åŒçš„å­—ä½“å‚æ•°"""
        img_copy = image.copy()
        draw = ImageDraw.Draw(img_copy)
        
        # è·å–å­—ä½“å‚æ•° - ä¸draw_text_box_at_centerä½¿ç”¨å®Œå…¨ç›¸åŒçš„é€»è¾‘
        font_size, box_width, box_height, text_width, text_height, font, padding = self.adjust_font_size_with_actual_measurement(
            text, image.width, image.height)
        
        # è®¡ç®—æ–‡æœ¬æ¡†çš„å·¦ä¸Šè§’ä½ç½®ï¼ˆä»¥center_x, center_yä¸ºä¸­å¿ƒï¼‰
        x = center_x - box_width // 2
        y = center_y - box_height // 2
        
        # ç¡®ä¿æ–‡æœ¬æ¡†å®Œå…¨åœ¨å›¾ç‰‡å†…
        x = max(0, min(x, image.width - box_width))
        y = max(0, min(y, image.height - box_height))
        
        # æ£€æµ‹èƒŒæ™¯è‰² - ä¸åŸæ–¹æ³•å®Œå…¨ç›¸åŒ
        background_color = self.get_average_color(image, x, y, box_width, box_height)
        text_color = self.get_contrasting_color(background_color)
        text_color_rgba = (*text_color, 255)
        
        # åˆ›å»ºå¸¦é€æ˜åº¦çš„è¦†ç›–å±‚
        overlay = Image.new('RGBA', img_copy.size, (255, 255, 255, 0))
        overlay_draw = ImageDraw.Draw(overlay)
        
        # è®¡ç®—æ–‡æœ¬åœ¨æ–‡æœ¬æ¡†ä¸­çš„ç²¾ç¡®å±…ä¸­ä½ç½® - ä¸åŸæ–¹æ³•å®Œå…¨ç›¸åŒ
        temp_bbox = overlay_draw.textbbox((0, 0), text, font=font)
        text_actual_width = temp_bbox[2] - temp_bbox[0]
        text_actual_height = temp_bbox[3] - temp_bbox[1]
        text_offset_y = temp_bbox[1]  # æ–‡æœ¬é¡¶éƒ¨åˆ°åŸºçº¿çš„åç§»
        
        # æ°´å¹³å±…ä¸­ï¼šæ–‡æœ¬æ¡†ä¸­å¿ƒ - æ–‡æœ¬å®é™…å®½åº¦çš„ä¸€åŠ
        text_x = x + (box_width - text_actual_width) // 2
        
        # å‚ç›´å±…ä¸­ï¼šè€ƒè™‘å­—ä½“çš„ascentå’Œdescentï¼Œç¡®ä¿æ–‡æœ¬è§†è§‰ä¸Šå±…ä¸­
        text_y = y + (box_height - text_actual_height) // 2 - text_offset_y
        
        # æ ¹æ®å­—ä½“å¤§å°è°ƒæ•´æè¾¹æ•ˆæœ - ä¸åŸæ–¹æ³•å®Œå…¨ç›¸åŒ
        outline_color = (0, 0, 0, 255) if text_color != (0, 0, 0) else (255, 255, 255, 255)
        
        # å°å­—ä½“ä½¿ç”¨æ›´ç»†çš„æè¾¹
        if font_size < 16:
            outline_width = 1
            # åªç»˜åˆ¶4ä¸ªæ–¹å‘çš„æè¾¹,å‡å°‘ç²˜è¿
            outline_positions = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        else:
            outline_width = 2
            # å¤§å­—ä½“ä½¿ç”¨8æ–¹å‘æè¾¹
            outline_positions = [(-outline_width, -outline_width), (-outline_width, 0), (-outline_width, outline_width),
                               (0, -outline_width), (0, outline_width),
                               (outline_width, -outline_width), (outline_width, 0), (outline_width, outline_width)]
        
        # ç»˜åˆ¶æè¾¹
        for dx, dy in outline_positions:
            overlay_draw.text((text_x + dx, text_y + dy), text, 
                            fill=outline_color, font=font)
        
        # ç»˜åˆ¶ä¸»æ–‡æœ¬
        overlay_draw.text((text_x, text_y), text, fill=text_color_rgba, font=font)
        
        # åˆå¹¶å›¾åƒ
        img_copy = Image.alpha_composite(img_copy.convert('RGBA'), overlay).convert('RGB')
        
        return img_copy, {
            'text': text,
            'center_position': (center_x, center_y),
            'text_position': (text_x, text_y),
            'background_color': background_color,
            'text_color': text_color,
            'font_size': font_size
        }

# åˆå§‹åŒ–ç»„ä»¶
prompt_generator = ObjectPromptGenerator()
text_drawer = TextBoxDrawer()


def get_object_position_and_size(edited_image, object_name, input_width, input_height):
    """è°ƒç”¨APIè·å–ç‰©ä½“åœ¨ç¼–è¾‘åå›¾ç‰‡ä¸­çš„ä½ç½®åæ ‡å’Œå¤§å°ä¿¡æ¯"""
    position_prompt = f"The size of this image is {input_width}*{input_height}. Please locate the bounding box of the object {object_name} in the image."\
    "The bounding box should be a rectangle that tightly encloses the object.Output only the bounding box coordinates in the format: (x1, y1, x2, y2)."\
    "x1 and y1 represent the coordinates of the upper left corner of the rectangle.x2 and y2 represent the coordinates of the lower right corner of the rectangle."\
    "All coordinates are in pixels, and the origin (0, 0) is the upper left corner of the image.You only need to output the final answer."
    
    try:
        result = edit_api(position_prompt, [edited_image])
        print(f"APIè¿”å›ç»“æœ: {result}")
        
        # é¦–å…ˆå°è¯•åŒ¹é…æ–°çš„ (x1, y1, x2, y2) æ ¼å¼
        bbox_pattern = r'\((\d+),\s*(\d+),\s*(\d+),\s*(\d+)\)'
        bbox_match = re.search(bbox_pattern, result)
        
        if bbox_match:
            x1, y1, x2, y2 = int(bbox_match.group(1)), int(bbox_match.group(2)), int(bbox_match.group(3)), int(bbox_match.group(4))
            
            # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡® (x1 < x2, y1 < y2)
            if x1 > x2:
                x1, x2 = x2, x1
            if y1 > y2:
                y1, y2 = y2, y1
            
            # ç¡®ä¿åæ ‡åœ¨å›¾ç‰‡èŒƒå›´å†…
            x1 = max(0, min(x1, input_width - 1))
            y1 = max(0, min(y1, input_height - 1))
            x2 = max(x1 + 1, min(x2, input_width))
            y2 = max(y1 + 1, min(y2, input_height))
            
            print(f"æå–åˆ°çš„è¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
            return x1, y1, x2, y2
        
        else:
            # å›é€€åˆ°æ—§çš„è§£ææ–¹å¼ä½œä¸ºå…¼å®¹æ€§å¤„ç†
            # åŒ¹é… Position: (x,y), Size: (width,height) æ ¼å¼
            position_size_pattern = r'Position:\s*\((\d+),\s*(\d+)\),\s*Size:\s*\((\d+),\s*(\d+)\)'
            match = re.search(position_size_pattern, result, re.IGNORECASE)
            
            if match:
                x, y, width, height = int(match.group(1)), int(match.group(2)), int(match.group(3)), int(match.group(4))
                # ç¡®ä¿åæ ‡åœ¨å›¾ç‰‡èŒƒå›´å†…
                x = max(0, min(x, input_width - 1))
                y = max(0, min(y, input_height - 1))
                # ç¡®ä¿å¤§å°åˆç†
                width = max(10, min(width, input_width))
                height = max(10, min(height, input_height))
                # è½¬æ¢ä¸ºè¾¹ç•Œæ¡†åæ ‡
                x1, y1 = x, y
                x2, y2 = x + width, y + height
                print(f"ä½¿ç”¨æ—§æ ¼å¼æå–åˆ°çš„ä½ç½®å’Œå¤§å°: ä½ç½®({x}, {y}), å¤§å°({width}, {height})")
                print(f"è½¬æ¢ä¸ºè¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
                return x1, y1, x2, y2
            else:
                # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å®Œæ•´æ ¼å¼ï¼Œå°è¯•åˆ†åˆ«åŒ¹é…ä½ç½®å’Œå¤§å°
                # åŒ¹é…ä½ç½® (æ•°å­—,æ•°å­—) æ ¼å¼
                coord_pattern = r'\((\d+),\s*(\d+)\)'
                coord_matches = re.findall(coord_pattern, result)
                
                # åŒ¹é…å¤§å°ç›¸å…³çš„æ•°å­—
                size_pattern = r'(?:width|w):\s*(\d+).*?(?:height|h):\s*(\d+)'
                size_match = re.search(size_pattern, result, re.IGNORECASE)
                
                if coord_matches and size_match:
                    x, y = int(coord_matches[0][0]), int(coord_matches[0][1])
                    width, height = int(size_match.group(1)), int(size_match.group(2))
                    # ç¡®ä¿æ•°å€¼åœ¨åˆç†èŒƒå›´å†…
                    x = max(0, min(x, input_width - 1))
                    y = max(0, min(y, input_height - 1))
                    width = max(10, min(width, input_width))
                    height = max(10, min(height, input_height))
                    # è½¬æ¢ä¸ºè¾¹ç•Œæ¡†åæ ‡
                    x1, y1 = x, y
                    x2, y2 = x + width, y + height
                    print(f"åˆ†åˆ«æå–åˆ°çš„ä½ç½®å’Œå¤§å°: ä½ç½®({x}, {y}), å¤§å°({width}, {height})")
                    print(f"è½¬æ¢ä¸ºè¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
                    return x1, y1, x2, y2
                elif coord_matches:
                    # åªæœ‰ä½ç½®ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å¤§å°
                    x, y = int(coord_matches[0][0]), int(coord_matches[0][1])
                    x = max(0, min(x, input_width - 1))
                    y = max(0, min(y, input_height - 1))
                    # ä½¿ç”¨é»˜è®¤å¤§å°ï¼ˆå›¾ç‰‡çš„10%ï¼‰
                    default_width = max(50, input_width // 10)
                    default_height = max(50, input_height // 10)
                    # è½¬æ¢ä¸ºè¾¹ç•Œæ¡†åæ ‡
                    x1, y1 = x, y
                    x2, y2 = x + default_width, y + default_height
                    print(f"åªæå–åˆ°ä½ç½®: ({x}, {y})ï¼Œä½¿ç”¨é»˜è®¤å¤§å°({default_width}, {default_height})")
                    print(f"è½¬æ¢ä¸ºè¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
                    return x1, y1, x2, y2
                else:
                    print("âŒ æ— æ³•ä»APIç»“æœä¸­æå–ä½ç½®å’Œå¤§å°ä¿¡æ¯,ä½¿ç”¨é»˜è®¤å€¼")
                    # ä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒå’Œé»˜è®¤å¤§å°
                    center_x, center_y = input_width // 2, input_height // 2
                    default_width = max(50, input_width // 10)
                    default_height = max(50, input_height // 10)
                    x1 = center_x - default_width // 2
                    y1 = center_y - default_height // 2
                    x2 = x1 + default_width
                    y2 = y1 + default_height
                    return x1, y1, x2, y2
                
    except Exception as e:
        print(f"âŒ è°ƒç”¨APIè·å–ä½ç½®å’Œå¤§å°æ—¶å‡ºé”™: {e},ä½¿ç”¨é»˜è®¤å€¼")
        # ä½¿ç”¨å›¾ç‰‡ä¸­å¿ƒå’Œé»˜è®¤å¤§å°
        center_x, center_y = input_width // 2, input_height // 2
        default_width = max(50, input_width // 10)
        default_height = max(50, input_height // 10)
        x1 = center_x - default_width // 2
        y1 = center_y - default_height // 2
        x2 = x1 + default_width
        y2 = y1 + default_height
        return x1, y1, x2, y2

def initialize_pipeline():
    """åˆå§‹åŒ–å›¾åƒç¼–è¾‘ç®¡é“"""
    # æœ¬åœ°æ¨¡å‹è·¯å¾„ - è¯·æ ¹æ®æ‚¨çš„å®é™…è·¯å¾„ä¿®æ”¹
    # local_model_path = "/storage/v-jinpewang/lab_folder/junchao/pretrained/Qwen-Image-Edit"
    pipeline = MyQwenImageEditPipeline.from_pretrained("Qwen/Qwen-Image-Edit-2509", torch_dtype=torch.bfloat16, cache_dir="/tmp")
    
    pipeline.transformer.to(torch.float32)
    pipeline.vae.to("cuda:0")
    pipeline.text_encoder.to("cuda:0")
    total_blocks = len(pipeline.transformer.transformer_blocks)
    gpu_split_points = [total_blocks//3, 2*total_blocks//3]  # ä¸‰ç­‰åˆ†
    pipeline.transformer = MultiGPUTransformer(pipeline.transformer, gpu_split_points)

    pipeline.set_progress_bar_config(disable=None)
    print("pipeline loaded")
    return pipeline


def process_single_image(pipeline, image_path, with_textbox_input_dir, with_textbox_output_dir, 
                         wo_textbox_input_dir, wo_textbox_output_dir, prompt_generator, text_drawer):
    """å¤„ç†å•å¼ å›¾ç‰‡ï¼Œç”Ÿæˆä¸¤ç§ç‰ˆæœ¬ï¼ˆå¸¦è¾¹ç•Œæ¡†å’Œåªæœ‰æ–‡æœ¬ï¼‰"""
    # 1. è¯»å–åŸå§‹å›¾ç‰‡
    original_image = Image.open(image_path).convert("RGB")
    input_width, input_height = original_image.size
    print(f"å¤„ç†å›¾ç‰‡: {image_path}, å°ºå¯¸: {input_width} x {input_height}")
    
    # 2. ç”Ÿæˆéšæœºç‰©ä½“æ·»åŠ çš„promptï¼ˆä¸å¸¦ä½ç½®ä¿¡æ¯ï¼‰
    object_prompt, object_name = prompt_generator.generate_unique_object_prompt()
    print(f"ç”Ÿæˆçš„ç‰©ä½“prompt: {object_prompt}")
    print(f"ç‰©ä½“åç§°: {object_name}")
    
    # 3. ç›´æ¥ä½¿ç”¨ä¿®æ”¹çš„promptè¿›è¡Œæ¨ç†
    constraints = ".It is crucial to adhere to the following constraints: " \
            "1. Keep all the original elements and areas in the image completely unchanged. You can only add objects on this basis. " \
            "2. Maintain the original camera angle, perspective, and zoom level without any changes. Ensure the edit integrates naturally with the existing scene. "
    prompt = f"{object_prompt} {constraints}"
    polished_prompt = polish_edit_prompt(prompt, original_image)
    print(f"ä½¿ç”¨çš„æ¨ç†prompt: {polished_prompt}")
    
    inputs = {
        "image": original_image,
        "prompt": prompt,
        "generator": torch.Generator(device="cuda").manual_seed(0),
        "true_cfg_scale": 4.0,
        "negative_prompt": " ",
        "num_inference_steps": 25,
        "guidance_scale": 1.0,
    }

    # 4. æ‰§è¡Œæ¨ç†ç”Ÿæˆç¼–è¾‘åçš„å›¾ç‰‡
    with torch.inference_mode():
        output = pipeline(**inputs)
        output_image = output.images[0]
    
    # 5. å°†è¾“å‡ºå›¾ç‰‡resizeåˆ°ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸ï¼Œç”¨äºAPIè°ƒç”¨
    resized_output_image = output_image.resize((input_width, input_height), Image.LANCZOS)
    
    # 6. è°ƒç”¨APIè·å–ç‰©ä½“åœ¨ç¼–è¾‘åå›¾ç‰‡ä¸­çš„è¾¹ç•Œæ¡†åæ ‡
    print("\nğŸ“ è°ƒç”¨APIï¼šè·å–è¾¹ç•Œæ¡†åæ ‡...")
    x1, y1, x2, y2 = get_object_position_and_size(
        resized_output_image, object_name, input_width, input_height)
    print(f"è·å–åˆ°çš„è¾¹ç•Œæ¡†åæ ‡: ({x1}, {y1}, {x2}, {y2})")

    # 7. ä»è¾¹ç•Œæ¡†åæ ‡è®¡ç®—ç‰©ä½“ä¸­å¿ƒä½ç½®ï¼ˆç”¨äºç»˜åˆ¶æ–‡æœ¬ï¼‰
    textbox_center_x = (x1 + x2) // 2
    textbox_center_y = (y1 + y2) // 2
    print(f"è®¡ç®—å¾—åˆ°çš„ä¸­å¿ƒä½ç½®: ({textbox_center_x}, {textbox_center_y})")

    # 8. åœ¨åŸå§‹å›¾ç‰‡ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å¹¶æ·»åŠ æ–‡å­—æ ‡ç­¾
    print("\nğŸ¨ ç»˜åˆ¶å¸¦è¾¹ç•Œæ¡†çš„å›¾ç‰‡...")
    with_bbox_image, textbox_info = text_drawer.draw_bounding_box_with_text(
        original_image, x1, y1, x2, y2, object_prompt)  # TODOï¼š ä¸ºä»€ä¹ˆè¿™é‡Œä¸ç”¨ polished_promptï¼Ÿ
    
    # 9. åœ¨åŸå§‹å›¾ç‰‡ä¸Šåªç»˜åˆ¶æ–‡æœ¬ï¼ˆæ— è¾¹æ¡†ï¼‰
    print("ğŸ¨ ç»˜åˆ¶åªæœ‰æ–‡æœ¬çš„å›¾ç‰‡...")
    text_only_image, text_only_info = text_drawer.draw_text_only_at_center(
        original_image, object_prompt, textbox_center_x, textbox_center_y)

    # 10. ä¿å­˜å››å¼ å›¾ç‰‡
    base_name = os.path.basename(image_path)
    name_without_ext = os.path.splitext(base_name)[0]
    ext = os.path.splitext(base_name)[1]
    
    print("\nğŸ’¾ ä¿å­˜å›¾ç‰‡...")
    
    # ä¿å­˜åˆ° with_textbox æ–‡ä»¶å¤¹
    # input: å¸¦è¾¹ç•Œæ¡†çš„åŸå§‹å›¾ç‰‡
    with_bbox_input_path = os.path.join(with_textbox_input_dir, f"{name_without_ext}_textbox{ext}")
    if with_bbox_image.size != (512, 512):
        resized_with_bbox = with_bbox_image.resize((512, 512), Image.LANCZOS)
        resized_with_bbox.save(with_bbox_input_path)
    else:
        with_bbox_image.save(with_bbox_input_path)
    
    # output: ç¼–è¾‘åçš„å›¾ç‰‡
    with_bbox_output_path = os.path.join(with_textbox_output_dir, f"{name_without_ext}_edited{ext}")
    resized_output_image.save(with_bbox_output_path)
    
    # ä¿å­˜åˆ° wo_textbox æ–‡ä»¶å¤¹
    # input: åªæœ‰æ–‡æœ¬çš„åŸå§‹å›¾ç‰‡
    text_only_input_path = os.path.join(wo_textbox_input_dir, f"{name_without_ext}_text_only{ext}")
    if text_only_image.size != (512, 512):
        resized_text_only = text_only_image.resize((512, 512), Image.LANCZOS)
        resized_text_only.save(text_only_input_path)
    else:
        text_only_image.save(text_only_input_path)
    
    # output: ç¼–è¾‘åçš„å›¾ç‰‡ï¼ˆä¸with_textboxçš„outputç›¸åŒï¼‰
    text_only_output_path = os.path.join(wo_textbox_output_dir, f"{name_without_ext}_edited{ext}")
    resized_output_image.save(text_only_output_path)
    
    # è¿”å›å¤„ç†ç»“æœ
    result = {
        'input_file': base_name,
        'object_prompt': object_prompt,
        'object_name': object_name,
        'polished_prompt': polished_prompt,
        'bounding_box': (x1, y1, x2, y2),
        'text_center': (textbox_center_x, textbox_center_y),
        'with_bbox_input_path': with_bbox_input_path,
        'with_bbox_output_path': with_bbox_output_path,
        'text_only_input_path': text_only_input_path,
        'text_only_output_path': text_only_output_path,
        'textbox_info': textbox_info,
        'text_only_info': text_only_info,
        'success': True
    }
    
    print(f"âœ… æˆåŠŸå¤„ç†: {base_name}")
    print(f"   ğŸ“ with_textbox/input: {with_bbox_input_path}")
    print(f"   ğŸ“ with_textbox/output: {with_bbox_output_path}")
    print(f"   ğŸ“ wo_textbox/input: {text_only_input_path}")
    print(f"   ğŸ“ wo_textbox/output: {text_only_output_path}")
    print(f"   ğŸ·ï¸  ç‰©ä½“prompt: {object_prompt}")
    print(f"   ğŸ¯ ç‰©ä½“åç§°: {object_name}")
    print(f"   ğŸ“¦ è¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")
    print(f"   ğŸ“ ä¸­å¿ƒä½ç½®: ({textbox_center_x}, {textbox_center_y})")
    
    return result


def print_results_summary(results, base_dir, results_path, max_images=None):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    successful = sum(1 for r in results if r.get('success', False))
    failed = len(results) - successful

    print(f"\n" + "="*80)
    print(f"å¤„ç†å®Œæˆ!")
    print(f"="*80)
    if max_images is not None:
        print(f"è®¾ç½®é™åˆ¶: æœ€å¤šå¤„ç† {max_images} å¼ å›¾ç‰‡")
    print(f"å®é™…å¤„ç†: {len(results)} å¼ å›¾ç‰‡")
    print(f"æˆåŠŸå¤„ç†: {successful} å¼ å›¾ç‰‡")
    print(f"å¤„ç†å¤±è´¥: {failed} å¼ å›¾ç‰‡")

    if successful > 0:
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        # ç»Ÿè®¡ä½¿ç”¨çš„ç‰©ä½“ç±»å‹
        object_counts = {}
        for result in results:
            if result.get('success', False):
                object_name = result.get('object_name', '')
                if object_name:
                    object_counts[object_name] = object_counts.get(object_name, 0) + 1
        
        if object_counts:
            print("   æœ€å¸¸ç”¨çš„ç‰©ä½“:")
            for obj, count in sorted(object_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"     - {obj}: {count} æ¬¡")
    print(f"="*80)


def main(max_images=None):
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå›¾åƒç¼–è¾‘å¤„ç†æµç¨‹
    
    Args:
        max_images (int, optional): æœ€å¤§å¤„ç†å›¾ç‰‡æ•°é‡é™åˆ¶,Noneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å›¾ç‰‡
    """
    # åˆå§‹åŒ–ç®¡é“
    pipeline = initialize_pipeline()
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºç›®å½•
    input_dir = "/storage/v-jinpewang/lab_folder/junchao/data/cluster_unprocessed_ultraedit/1/0/"
    
    # åˆ›å»ºåŸºç¡€è¾“å‡ºç›®å½•
    base_output_dir = "/storage/v-jinpewang/lab_folder/junchao/data/image_eidt_dataset/processed_data_Accgen"
    
    # åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„
    with_textbox_dir = os.path.join(base_output_dir, "with_textbox")
    with_textbox_input_dir = os.path.join(with_textbox_dir, "input")
    with_textbox_output_dir = os.path.join(with_textbox_dir, "output")
    
    wo_textbox_dir = os.path.join(base_output_dir, "wo_textbox")
    wo_textbox_input_dir = os.path.join(wo_textbox_dir, "input")
    wo_textbox_output_dir = os.path.join(wo_textbox_dir, "output")
    
    # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
    os.makedirs(with_textbox_input_dir, exist_ok=True)
    os.makedirs(with_textbox_output_dir, exist_ok=True)
    os.makedirs(wo_textbox_input_dir, exist_ok=True)
    os.makedirs(wo_textbox_output_dir, exist_ok=True)

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    all_paths = sorted(glob.glob(os.path.join(input_dir, "*")))
    image_files = [
        p for p in all_paths
        if os.path.isfile(p) and os.path.splitext(p)[1].lower() in {".png", ".jpg", ".jpeg"}
    ]
    
    # åº”ç”¨å›¾ç‰‡æ•°é‡é™åˆ¶
    if max_images is not None and max_images > 0:
        image_files = image_files[:max_images]
        print(f"\nğŸ“Š è®¾ç½®å¤„ç†å›¾ç‰‡æ•°é‡é™åˆ¶: {max_images} å¼ ")
    
    print(f"ğŸ“ æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {len(image_files)} å¼ \n")

    # ä¿å­˜å¤„ç†ç»“æœ
    results = []

    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for i, image_path in enumerate(tqdm(image_files, desc="å¤„ç†å›¾ç‰‡")):
        try:
            result = process_single_image(
                pipeline, image_path, 
                with_textbox_input_dir, with_textbox_output_dir,
                wo_textbox_input_dir, wo_textbox_output_dir,
                prompt_generator, text_drawer
            )
            results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™åˆ¶ï¼ˆé¢å¤–çš„å®‰å…¨æ£€æŸ¥ï¼‰
            if max_images is not None and len(results) >= max_images:
                print(f"\nâœ… å·²è¾¾åˆ°å¤„ç†å›¾ç‰‡æ•°é‡é™åˆ¶ ({max_images} å¼ )ï¼Œåœæ­¢å¤„ç†")
                break
                
        except Exception as e:
            print(f"\nâŒ å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            result = {
                'input_file': os.path.basename(image_path),
                'error': str(e),
                'success': False
            }
            results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™åˆ¶ï¼ˆåŒ…å«é”™è¯¯çš„æƒ…å†µï¼‰
            if max_images is not None and len(results) >= max_images:
                print(f"\nâœ… å·²è¾¾åˆ°å¤„ç†å›¾ç‰‡æ•°é‡é™åˆ¶ ({max_images} å¼ )ï¼Œåœæ­¢å¤„ç†")
                break

    # ä¿å­˜å¤„ç†ç»“æœåˆ°JSONæ–‡ä»¶
    results_path = os.path.join(base_output_dir, "processing_results.json")
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # æ‰“å°ç»“æœæ‘˜è¦
    print_results_summary(results, base_output_dir, results_path, max_images)


if __name__ == "__main__":
    # ä¿®æ”¹è¿™ä¸ªæ•°å­—æ¥é™åˆ¶å¤„ç†çš„å›¾ç‰‡æ•°é‡ï¼Œè®¾ç½®ä¸ºNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å›¾ç‰‡
    MAX_IMAGES_LIMIT = None
    
    main(max_images=MAX_IMAGES_LIMIT) 