# '''
# ä½¿ç”¨qwen-image-editä¸ºå›¾ç‰‡æ·»åŠ doodleæ•ˆæœï¼Œç„¶åè½¬æ¢ä¸ºçœŸå®å›¾ç‰‡
# ä¸ºå›¾ä¸­çš„elephantæ·»åŠ ä¸€ä¸ªæ¶‚é¸¦ç»˜åˆ¶çš„å¸½å­ï¼Œç„¶åå°†doodleè½¬æ¢ä¸ºçœŸå®çš„å¸½å­
# '''
# import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"
# import torch
# from PIL import Image
# from multi3_infer_plus import MyQwenImageEditPipeline, MultiGPUTransformer
# from prompt_utils import polish_edit_prompt


# def initialize_pipeline():
#     """åˆå§‹åŒ–å›¾åƒç¼–è¾‘ç®¡é“"""
#     print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
#     pipeline = MyQwenImageEditPipeline.from_pretrained(
#         "Qwen/Qwen-Image-Edit-2509", 
#         torch_dtype=torch.bfloat16, 
#         cache_dir="/tmp"
#     )
    
#     # è®¾ç½®æ¨¡å‹ç²¾åº¦å’Œè®¾å¤‡
#     pipeline.transformer.to(torch.float32)
#     pipeline.vae.to("cuda:0")
#     pipeline.text_encoder.to("cuda:0")
    
#     # é…ç½®å¤šGPUåˆ†å¸ƒ
#     total_blocks = len(pipeline.transformer.transformer_blocks)
#     gpu_split_points = [total_blocks//3, 2*total_blocks//3]  # ä¸‰ç­‰åˆ†
#     pipeline.transformer = MultiGPUTransformer(pipeline.transformer, gpu_split_points)
    
#     pipeline.set_progress_bar_config(disable=None)
#     print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
#     return pipeline


# def add_doodle_hat(image_path, output_path, pipeline):
#     """ä¸ºå›¾ä¸­çš„elephantæ·»åŠ æ¶‚é¸¦å¸½å­"""
#     # è¯»å–å›¾ç‰‡
#     print(f"ğŸ“– è¯»å–å›¾ç‰‡: {image_path}")
#     original_image = Image.open(image_path).convert("RGB")
#     input_width, input_height = original_image.size
#     print(f"   å›¾ç‰‡å°ºå¯¸: {input_width} x {input_height}")
    
#     # è®¾ç½®prompt
#     original_prompt = "Add a hat on the elephant in the image using only simple, rough outline strokes. The hat should be drawn with minimal lines - just basic contours and shapes, like a quick sketch. No shading, no details, no filling - only simple line outlines. Keep everything else exactly the same as the original image, maintaining complete consistency except for the added hat outline."
#     print(f"ğŸ“ åŸå§‹ç¼–è¾‘æŒ‡ä»¤: {original_prompt}")
    
#     # ä½¿ç”¨polish_edit_promptæ¶¦è‰²prompt
#     polished_prompt = polish_edit_prompt(original_prompt, original_image)
#     print(f"âœ¨ æ¶¦è‰²åçš„æŒ‡ä»¤: {polished_prompt}")
    
#     # å‡†å¤‡æ¨ç†å‚æ•°
#     inputs = {
#         "image": original_image,
#         "prompt": polished_prompt,
#         "generator": torch.Generator(device="cuda").manual_seed(0),
#         "true_cfg_scale": 4.0,
#         "negative_prompt": " ",
#         "num_inference_steps": 25,  # å‚è€ƒadd_with_textbox.pyçš„è®¾ç½®
#         "guidance_scale": 1.0,
#     }
    
#     # æ‰§è¡Œæ¨ç†
#     print("ğŸ¨ å¼€å§‹ç”Ÿæˆ...")
#     with torch.inference_mode():
#         output = pipeline(**inputs)
#         output_image = output.images[0]
    
#     # å°†è¾“å‡ºå›¾ç‰‡resizeåˆ°ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸
#     resized_output_image = output_image.resize((input_width, input_height), Image.LANCZOS)
    
#     # ä¿å­˜ç»“æœ
#     resized_output_image.save(output_path)
#     print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {output_path}")
    
#     return resized_output_image


# def convert_doodle_to_realistic(doodle_image_path, output_path, pipeline):
#     """å°†doodleå›¾ç‰‡è½¬æ¢ä¸ºçœŸå®çš„å›¾ç‰‡"""
#     # è¯»å–doodleå›¾ç‰‡
#     print(f"ğŸ“– è¯»å–doodleå›¾ç‰‡: {doodle_image_path}")
#     doodle_image = Image.open(doodle_image_path).convert("RGB")
#     input_width, input_height = doodle_image.size
#     print(f"   å›¾ç‰‡å°ºå¯¸: {input_width} x {input_height}")
    
#     # è®¾ç½®prompt - å°†doodleè½¬ä¸ºçœŸå®
#     original_prompt = "Convert the doodle-style hat into a realistic, photorealistic hat. Keep everything else exactly the same as the original, maintaining complete consistency."
#     print(f"ğŸ“ åŸå§‹ç¼–è¾‘æŒ‡ä»¤: {original_prompt}")
    
#     # ä½¿ç”¨polish_edit_promptæ¶¦è‰²prompt
#     polished_prompt = polish_edit_prompt(original_prompt, doodle_image)
#     print(f"âœ¨ æ¶¦è‰²åçš„æŒ‡ä»¤: {polished_prompt}")
    
#     # å‡†å¤‡æ¨ç†å‚æ•°
#     inputs = {
#         "image": doodle_image,
#         "prompt": polished_prompt,
#         "generator": torch.Generator(device="cuda").manual_seed(0),
#         "true_cfg_scale": 4.0,
#         "negative_prompt": " ",
#         "num_inference_steps": 25,  # å‚è€ƒadd_with_textbox.pyçš„è®¾ç½®
#         "guidance_scale": 1.0,
#     }
    
#     # æ‰§è¡Œæ¨ç†
#     print("ğŸ¨ å¼€å§‹ç”ŸæˆçœŸå®å›¾ç‰‡...")
#     with torch.inference_mode():
#         output = pipeline(**inputs)
#         output_image = output.images[0]
    
#     # å°†è¾“å‡ºå›¾ç‰‡resizeåˆ°ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸
#     resized_output_image = output_image.resize((input_width, input_height), Image.LANCZOS)
    
#     # ä¿å­˜ç»“æœ
#     resized_output_image.save(output_path)
#     print(f"âœ… çœŸå®å›¾ç‰‡å·²ä¿å­˜: {output_path}")
    
#     return resized_output_image


# def main():
#     """ä¸»å‡½æ•°"""
#     # è®¾ç½®è·¯å¾„
#     script_dir = os.path.dirname(os.path.abspath(__file__))
#     original_image_path = os.path.join(script_dir, "imgs/image.png")
    
#     # åˆ›å»ºinputå’Œoutputç›®å½•åœ¨imgsä¸‹
#     input_dir = os.path.join(script_dir, "imgs/input")
#     output_dir = os.path.join(script_dir, "imgs/output")
#     os.makedirs(input_dir, exist_ok=True)
#     os.makedirs(output_dir, exist_ok=True)
    
#     # è®¾ç½®è¾“å‡ºè·¯å¾„
#     doodle_image_path = os.path.join(input_dir, "image_with_doodle_hat.png")
#     realistic_image_path = os.path.join(output_dir, "image_with_realistic_hat.png")
    
#     # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     if not os.path.exists(original_image_path):
#         print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶ {original_image_path}")
#         return
    
#     # åˆå§‹åŒ–æ¨¡å‹
#     pipeline = initialize_pipeline()
    
#     # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆdoodleå›¾ç‰‡
#     print("\n" + "="*60)
#     print("æ­¥éª¤ 1/2: ç”Ÿæˆdoodleå¸½å­")
#     print("="*60)
#     add_doodle_hat(original_image_path, doodle_image_path, pipeline)
    
#     # # ç¬¬äºŒæ­¥ï¼šå°†doodleè½¬æ¢ä¸ºçœŸå®å›¾ç‰‡
#     # print("\n" + "="*60)
#     # print("æ­¥éª¤ 2/2: å°†doodleè½¬æ¢ä¸ºçœŸå®å¸½å­")
#     # print("="*60)
#     # convert_doodle_to_realistic(doodle_image_path, realistic_image_path, pipeline)
    
#     # print("\n" + "="*60)
#     # print("ï¿½ï¿½ å…¨éƒ¨å¤„ç†å®Œæˆï¼")
#     # print(f"ğŸ“ Doodleå›¾ç‰‡: {doodle_image_path}")
#     # print(f"ğŸ“ çœŸå®å›¾ç‰‡: {realistic_image_path}")
#     # print("="*60)


# if __name__ == "__main__":
#     main()

'''
ä½¿ç”¨qwen-image-editä¸ºå›¾ç‰‡æ·»åŠ doodleæ•ˆæœï¼Œç„¶åè½¬æ¢ä¸ºçœŸå®å›¾ç‰‡
ä¸ºå›¾ä¸­çš„elephantæ·»åŠ ä¸€ä¸ªæ¶‚é¸¦ç»˜åˆ¶çš„å¸½å­ï¼Œç„¶åå°†doodleè½¬æ¢ä¸ºçœŸå®çš„å¸½å­
'''
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"
import torch
import glob
import json
import random
import re
from PIL import Image
from multi3_infer_plus import MyQwenImageEditPipeline, MultiGPUTransformer
from prompt_utils import polish_edit_prompt


def slugify(text):
    """
    å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸€ä¸ªå®‰å…¨çš„æ–‡ä»¶åï¼ˆ"slug"ï¼‰ã€‚
    ä¾‹å¦‚ï¼š"a party hat" -> "a_party_hat"
    """
    text = text.lower()
    text = re.sub(r'[^a-z0-9\s-]', '', text)  # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[\s-]+', '_', text).strip('_') # æ›¿æ¢ç©ºæ ¼å’Œ-ä¸º_
    return text

def initialize_pipeline():
    """åˆå§‹åŒ–å›¾åƒç¼–è¾‘ç®¡é“"""
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    pipeline = MyQwenImageEditPipeline.from_pretrained(
        "Qwen/Qwen-Image-Edit-2509", 
        torch_dtype=torch.bfloat16, 
        cache_dir="/tmp"
    )
    
    # è®¾ç½®æ¨¡å‹ç²¾åº¦å’Œè®¾å¤‡
    pipeline.transformer.to(torch.float32)
    pipeline.vae.to("cuda:0")
    pipeline.text_encoder.to("cuda:0")
    
    # é…ç½®å¤šGPUåˆ†å¸ƒ
    total_blocks = len(pipeline.transformer.transformer_blocks)
    gpu_split_points = [total_blocks//3, 2*total_blocks//3]  # ä¸‰ç­‰åˆ†
    pipeline.transformer = MultiGPUTransformer(pipeline.transformer, gpu_split_points)
    
    pipeline.set_progress_bar_config(disable=None)
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return pipeline


def add_doodle_hat(image_path, output_path, pipeline,object_name):
    # è¯»å–å›¾ç‰‡
    print(f"ğŸ“– è¯»å–å›¾ç‰‡: {image_path}")
    original_image = Image.open(image_path).convert("RGB")
    input_width, input_height = original_image.size
    print(f"   å›¾ç‰‡å°ºå¯¸: {input_width} x {input_height}")
    
    # è®¾ç½®prompt
    print(f"ğŸ¨ ç›®æ ‡ç‰©ä½“: {object_name}")
    # original_prompt = f"Add {object_name} on the subject in the image using only simple, rough outline strokes. The {object_name} should be drawn with minimal lines - just basic contours and shapes, like a quick sketch. No shading, no details, no filling - only simple line outlines. Keep everything else exactly the same as the original image, maintaining complete consistency except for the added {object_name} outline."
#     original_prompt = (
#     f"Add {object_name} on the subject in the image. "
#     f"The {object_name} MUST be drawn using ONLY simple, rough outline strokes, like a quick sketch. "
#     f"NO shading, NO details, NO filling, ONLY simple line outlines for the {object_name}. "
#     f"CRITICALLY: The rest of the image, including the subject and background, "
#     f"MUST remain IDENTICAL to the original. "
#     f"Maintain the EXACT original photorealistic style, colors, and textures of EVERYTHING else. "
#     f"Absolutely NO changes to the subject or background's original appearance. "
#     f"ONLY add the {object_name} outline."
# )
    original_prompt = (
    f"Add {object_name} on the subject in the image."
    f"This {object_name} MUST be in a doodle-style, drawn using only simple, minimal lines for its basic contour. NO details, NO filling, NO shading, and NO color are allowed; only pure line outlines."
    f"CRITICAL REQUIREMENT: Aside from this added {object_name} line outline, ALL other parts of the imageâ€”including the subject and backgroundâ€”MUST remain 100% IDENTICAL to the original. You MUST strictly preserve the subject's original photorealistic style, all details, textures, and colors. Absolutely NO stylistic or content changes to the subject or background are permitted."
    f"CRITICAL REQUIREMENT: You MUST NOT add any lines, outlines, or style changes to the subject or the background. "
    )
    print(f"ğŸ“ åŸå§‹ç¼–è¾‘æŒ‡ä»¤: {original_prompt}")

    
    # ä½¿ç”¨polish_edit_promptæ¶¦è‰²prompt
    polished_prompt = polish_edit_prompt(original_prompt, original_image)
    print(f"âœ¨ æ¶¦è‰²åçš„æŒ‡ä»¤: {polished_prompt}")
    
    # å‡†å¤‡æ¨ç†å‚æ•°
    inputs = {
        "image": original_image,
        "prompt": polished_prompt,
        "generator": torch.Generator(device="cuda").manual_seed(0),
        "true_cfg_scale": 4.0,
        "negative_prompt": " ",
        "num_inference_steps": 25,  # å‚è€ƒadd_with_textbox.pyçš„è®¾ç½®
        "guidance_scale": 1.0,
    }
    
    # æ‰§è¡Œæ¨ç†
    print("ğŸ¨ å¼€å§‹ç”Ÿæˆ...")
    with torch.inference_mode():
        output = pipeline(**inputs)
        output_image = output.images[0]
    
    # å°†è¾“å‡ºå›¾ç‰‡resizeåˆ°ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸
    resized_output_image = output_image.resize((input_width, input_height), Image.LANCZOS)
    
    # ä¿å­˜ç»“æœ
    resized_output_image.save(output_path)
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {output_path}")
    
    return resized_output_image


def convert_doodle_to_realistic(doodle_image_path, output_path, pipeline,object_name):
    """å°†doodleå›¾ç‰‡è½¬æ¢ä¸ºçœŸå®çš„å›¾ç‰‡"""
    # è¯»å–doodleå›¾ç‰‡
    print(f"ğŸ“– è¯»å–doodleå›¾ç‰‡: {doodle_image_path}")
    doodle_image = Image.open(doodle_image_path).convert("RGB")
    input_width, input_height = doodle_image.size
    print(f"   å›¾ç‰‡å°ºå¯¸: {input_width} x {input_height}")
    
    # è®¾ç½®prompt - å°†doodleè½¬ä¸ºçœŸå®
    print(f"ğŸ¨ ç›®æ ‡ç‰©ä½“: {object_name}")
    # original_prompt = f"Convert the doodle-style {object_name} into a realistic, photorealistic {object_name}. Keep everything else exactly the same as the original, maintaining complete consistency."
    original_prompt = (
        f"Convert the doodle-style {object_name} on the subject into a realistic, photorealistic {object_name}."
        f"CRITICAL REQUIREMENT: The rest of the imageâ€”including the subject's appearance, its exact colors, textures, and the entire backgroundâ€”MUST remain 100% IDENTICAL to the original base image (before any doodle was added). Strictly preserve the original photorealistic style, brightness, contrast, and color vividness of EVERYTHING except the {object_name}. Absolutely NO changes to the subject or background's original pixel data, only render the {object_name} realistically."
    )
    print(f"ğŸ“ åŸå§‹ç¼–è¾‘æŒ‡ä»¤: {original_prompt}")
    
    # ä½¿ç”¨polish_edit_promptæ¶¦è‰²prompt
    polished_prompt = polish_edit_prompt(original_prompt, doodle_image)
    print(f"âœ¨ æ¶¦è‰²åçš„æŒ‡ä»¤: {polished_prompt}")
    
    # å‡†å¤‡æ¨ç†å‚æ•°
    inputs = {
        "image": doodle_image,
        "prompt": polished_prompt,
        "generator": torch.Generator(device="cuda").manual_seed(0),
        "true_cfg_scale": 4.0,
        "negative_prompt": " ",
        "num_inference_steps": 25,  # å‚è€ƒadd_with_textbox.pyçš„è®¾ç½®
        "guidance_scale": 1.0,
    }
    
    # æ‰§è¡Œæ¨ç†
    print("ğŸ¨ å¼€å§‹ç”ŸæˆçœŸå®å›¾ç‰‡...")
    with torch.inference_mode():
        output = pipeline(**inputs)
        output_image = output.images[0]
    
    # å°†è¾“å‡ºå›¾ç‰‡resizeåˆ°ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸
    resized_output_image = output_image.resize((input_width, input_height), Image.LANCZOS)
    
    # ä¿å­˜ç»“æœ
    resized_output_image.save(output_path)
    print(f"âœ… çœŸå®å›¾ç‰‡å·²ä¿å­˜: {output_path}")
    
    return resized_output_image


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # original_image_path = os.path.join(script_dir, "imgs/image.png")
    original_images_dir = os.path.join(script_dir, "imgs_test/originals")
    json_config_path = os.path.join(script_dir, "edit_doodles.json")
    
    # åˆ›å»ºinputå’Œoutputç›®å½•åœ¨imgsä¸‹
    input_dir = os.path.join(script_dir, "imgs_test/input")
    output_dir = os.path.join(script_dir, "imgs_test/output")
    os.makedirs(input_dir, exist_ok=True)
    os.makedirs(output_dir, exist_ok=True)
    

    if not os.path.exists(json_config_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {json_config_path}")
        return
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(original_images_dir):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶ {original_images_dir}")
        return
    print(f"ğŸ“– æ­£åœ¨è¯»å–é…ç½®æ–‡ä»¶: {json_config_path}")
    with open(json_config_path, 'r') as f:
            config = json.load(f)
    objects_to_add = config.get("objects", [])
    if not objects_to_add:
        print("âŒ é”™è¯¯: JSONæ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'objects' åˆ—è¡¨æˆ–åˆ—è¡¨ä¸ºç©ºã€‚")
        return
    print(f"ğŸ” æ‰¾åˆ° {len(objects_to_add)} ä¸ªå¯ç”¨ç‰©ä½“: {objects_to_add}")

    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
    print(f"ğŸ“‚ æ­£åœ¨æ‰«ææºå›¾ç‰‡ç›®å½•: {original_images_dir}")
    image_extensions = ["*.png", "*.jpg", "*.jpeg", "*.webp"]
    all_image_paths = []
    for ext in image_extensions:
        all_image_paths.extend(glob.glob(os.path.join(original_images_dir, ext)))
        
    if not all_image_paths:
        print(f"âŒ é”™è¯¯: åœ¨ {original_images_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ã€‚")
        print(f"   (æ”¯æŒçš„æ ¼å¼: {', '.join(image_extensions)})")
        return
        
    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(all_image_paths)} å¼ å¾…å¤„ç†å›¾ç‰‡ã€‚")

    # åˆå§‹åŒ–æ¨¡å‹
    pipeline = initialize_pipeline()
    for i, original_image_path in enumerate(all_image_paths):
        print("\n" + "="*80)
        print(f"ğŸš€ å¼€å§‹å¤„ç†å›¾ç‰‡ {i+1}/{len(all_image_paths)}: {os.path.basename(original_image_path)}")
        print("="*80)
        
        random_object_name = random.choice(objects_to_add)
        print(f"ğŸ² ä¸ºæ­¤å›¾ç‰‡éšæœºé€‰æ‹©çš„ç‰©ä½“æ˜¯: {random_object_name}")
        
        # ä½¿ç”¨slugifyå’ŒåŸå§‹æ–‡ä»¶ååˆ›å»ºå”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶å
        object_slug = slugify(random_object_name)
        original_basename = os.path.splitext(os.path.basename(original_image_path))[0]
        # è®¾ç½®åŠ¨æ€è¾“å‡ºè·¯å¾„
        doodle_image_path = os.path.join(input_dir, f"{original_basename}_doodle_{object_slug}.png")
        realistic_image_path = os.path.join(output_dir, f"{original_basename}_realistic_{object_slug}.png")
    
        try:
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆdoodleå›¾ç‰‡
            print("\n" + "-"*60)
            print(f"æ­¥éª¤ 1/2: ç”Ÿæˆdoodle ({random_object_name})")
            print("-"*60)
            add_doodle_hat(original_image_path, doodle_image_path, pipeline, random_object_name)
            
            # ç¬¬äºŒæ­¥ï¼šå°†doodleè½¬æ¢ä¸ºçœŸå®å›¾ç‰‡
            print("\n" + "-"*60)
            print(f"æ­¥éª¤ 2/2: å°†doodleè½¬æ¢ä¸ºçœŸå® ({random_object_name})")
            print("-"*60)
            convert_doodle_to_realistic(doodle_image_path, realistic_image_path, pipeline, random_object_name)
            
            print("\n" + "âœ“"*60)
            print(f"ğŸ‰ å›¾ç‰‡ '{os.path.basename(original_image_path)}' å¤„ç†å®Œæˆï¼")
            print(f"   ğŸ“ Doodleå›¾ç‰‡: {doodle_image_path}")
            print(f"   ğŸ“ çœŸå®å›¾ç‰‡: {realistic_image_path}")
            print("âœ“"*60)

        except Exception as e:
            print(f"âŒâŒâŒ å¤„ç†å›¾ç‰‡ {original_image_path} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            print("å°†è·³è¿‡æ­¤å›¾ç‰‡ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª...")

    print("\n" + "="*80)
    print("âœ¨âœ¨âœ¨ å…¨éƒ¨ä»»åŠ¡å¤„ç†å®Œæˆï¼ âœ¨âœ¨âœ¨")
    print("="*80)


if __name__ == "__main__":
    main()






