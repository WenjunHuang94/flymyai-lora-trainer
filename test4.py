import torch
import time
# ã€ã€ã€ ä¿®æ”¹1ï¼šå¯¼å…¥æ¨¡å‹ç±»æœ¬èº« ã€‘ã€‘ã€‘
from diffusers import AutoencoderKLQwenImage, QwenImageTransformer2DModel
# ã€ã€ã€ ä¿®æ”¹2ï¼šå¯¼å…¥transformersçš„AutoConfigå’ŒQwen-VLçš„å…·ä½“æ¨¡å‹ç±» ã€‘ã€‘ã€‘
from transformers import AutoConfig, Qwen2_5_VLForConditionalGeneration
from transformers import logging as hf_logging

# å‹åˆ¶åŠ è½½æ¨¡å‹æ—¶çš„éå¿…è¦è­¦å‘Š
hf_logging.set_verbosity_error()

# --- é…ç½® ---
model_path = "Qwen/Qwen-Image"
# model_path = "Qwen/Qwen-Image-Edit"  # <--- ã€ã€è¯·ä¿®æ”¹æˆè¿™ä¸ªã€‘ã€‘

print(f"æ­£åœ¨ä» {model_path} åŠ è½½é…ç½®, å¹¶ä½¿ç”¨ 'meta' device å¿«é€Ÿå®ä¾‹åŒ–æ¶æ„...")
print("=" * 60 + "\n")

# è®°å½•æ€»å‚æ•°
total_params = 0
model_components = []

with torch.device("meta"):
    # --- 1. VAE (å˜åˆ†è‡ªç¼–ç å™¨) ---
    print("=" * 25 + " 1. VAE æ¶æ„ (AutoencoderKLQwenImage) " + "=" * 25)
    load_start = time.time()
    try:
        # ç¬¬1æ­¥ï¼šåŠ è½½é…ç½® (åŒè„šæœ¬1)
        vae_config = AutoencoderKLQwenImage.load_config(
            model_path,
            subfolder="vae"
        )

        # ã€ã€ã€ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ .from_config() ä»é…ç½®å®ä¾‹åŒ–æ¨¡å‹ ã€‘ã€‘ã€‘
        vae_model = AutoencoderKLQwenImage.from_config(vae_config)
        print(f"VAE æ¶æ„å®ä¾‹åŒ–å®Œæ¯• (è€—æ—¶: {time.time() - load_start:.4f}s)\n")

        # è®¡ç®—å‚æ•°é‡
        params = sum(p.numel() for p in vae_model.parameters())
        total_params += params

        # ä¼°ç®—æ˜¾å­˜å ç”¨
        # å‡è®¾ä½¿ç”¨ fp16 (float16)ï¼Œæ¯ä¸ªå‚æ•° 2 å­—èŠ‚
        mem_fp16 = params * 2 / (1024 ** 3)  # è½¬æ¢ä¸º GB
        # å‡è®¾ä½¿ç”¨ fp32 (float32)ï¼Œæ¯ä¸ªå‚æ•° 4 å­—èŠ‚
        mem_fp32 = params * 4 / (1024 ** 3)  # è½¬æ¢ä¸º GB
        # å‡è®¾ä½¿ç”¨ bf16 (bfloat16)ï¼Œæ¯ä¸ªå‚æ•° 2 å­—èŠ‚
        mem_bf16 = params * 2 / (1024 ** 3)  # è½¬æ¢ä¸º GB

        print(f"VAE å‚æ•°é‡: {params:,}")
        print(f"  â‰ˆ {params / 1e6:.2f}M å‚æ•°")
        print(f"  â‰ˆ {params / 1e9:.2f}B å‚æ•°")
        print("\næ˜¾å­˜å ç”¨ä¼°ç®— (ä»…æ¨¡å‹æƒé‡):")
        print(f"  - FP16: {mem_fp16:.2f} GB")
        print(f"  - BF16: {mem_bf16:.2f} GB")
        print(f"  - FP32: {mem_fp32:.2f} GB")
        print("\nå®é™…è®­ç»ƒæ—¶ä¼°ç®— (AdamWä¼˜åŒ–å™¨ + æ¢¯åº¦):")
        print(f"  - FP16æ··åˆç²¾åº¦: {mem_fp16 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")
        print(f"  - FP32è®­ç»ƒ: {mem_fp32 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")

        model_components.append(("VAE", params, mem_fp16, mem_fp32))

        print("\n" + "=" * 80 + "\n")

    except Exception as e:
        print(f"å®ä¾‹åŒ– VAE æ¶æ„å¤±è´¥: {e}")

    # --- 2. DiT (æ‰©æ•£ Transformer) ---
    print("=" * 20 + " 2. DiT æ¶æ„ (QwenImageTransformer2DModel) " + "=" * 20)
    load_start = time.time()
    try:
        # ç¬¬1æ­¥ï¼šåŠ è½½é…ç½®
        dit_config = QwenImageTransformer2DModel.load_config(
            model_path,
            subfolder="transformer"
        )

        # å®ä¾‹åŒ–æ¨¡å‹
        dit_model = QwenImageTransformer2DModel.from_config(dit_config)
        print(f"DiT æ¶æ„å®ä¾‹åŒ–å®Œæ¯• (è€—æ—¶: {time.time() - load_start:.4f}s)\n")

        # è®¡ç®—å‚æ•°é‡
        params = sum(p.numel() for p in dit_model.parameters())
        total_params += params

        # ä¼°ç®—æ˜¾å­˜å ç”¨
        mem_fp16 = params * 2 / (1024 ** 3)
        mem_fp32 = params * 4 / (1024 ** 3)
        mem_bf16 = params * 2 / (1024 ** 3)

        print(f"DiT å‚æ•°é‡: {params:,}")
        print(f"  â‰ˆ {params / 1e6:.2f}M å‚æ•°")
        print(f"  â‰ˆ {params / 1e9:.2f}B å‚æ•°")
        print("\næ˜¾å­˜å ç”¨ä¼°ç®— (ä»…æ¨¡å‹æƒé‡):")
        print(f"  - FP16: {mem_fp16:.2f} GB")
        print(f"  - BF16: {mem_bf16:.2f} GB")
        print(f"  - FP32: {mem_fp32:.2f} GB")
        print("\nå®é™…è®­ç»ƒæ—¶ä¼°ç®— (AdamWä¼˜åŒ–å™¨ + æ¢¯åº¦):")
        print(f"  - FP16æ··åˆç²¾åº¦: {mem_fp16 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")
        print(f"  - FP32è®­ç»ƒ: {mem_fp32 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")

        model_components.append(("DiT", params, mem_fp16, mem_fp32))

        print("\n" + "=" * 80 + "\n")

    except Exception as e:
        print(f"åŠ è½½ DiT æ¶æ„å¤±è´¥: {e}")

    # --- 3. Qwen-VL (æ–‡æœ¬ç¼–ç å™¨) ---
    print("=" * 20 + " 3. Qwen-VL æ¶æ„ (Text Encoder) " + "=" * 20)
    load_start = time.time()
    try:
        # ç¬¬1æ­¥ï¼šåŠ è½½é…ç½®
        vl_config = AutoConfig.from_pretrained(
            model_path,
            subfolder="text_encoder"
        )

        # å®ä¾‹åŒ–æ¨¡å‹
        from transformers import AutoModel

        vl_model = AutoModel.from_config(vl_config)
        print(f"Qwen-VL (Text Encoder) æ¶æ„å®ä¾‹åŒ–å®Œæ¯• (è€—æ—¶: {time.time() - load_start:.2f}s)\n")

        # è®¡ç®—å‚æ•°é‡
        params = sum(p.numel() for p in vl_model.parameters())
        total_params += params

        # ä¼°ç®—æ˜¾å­˜å ç”¨
        mem_fp16 = params * 2 / (1024 ** 3)
        mem_fp32 = params * 4 / (1024 ** 3)
        mem_bf16 = params * 2 / (1024 ** 3)

        print(f"Qwen-VL å‚æ•°é‡: {params:,}")
        print(f"  â‰ˆ {params / 1e6:.2f}M å‚æ•°")
        print(f"  â‰ˆ {params / 1e9:.2f}B å‚æ•°")
        print("\næ˜¾å­˜å ç”¨ä¼°ç®— (ä»…æ¨¡å‹æƒé‡):")
        print(f"  - FP16: {mem_fp16:.2f} GB")
        print(f"  - BF16: {mem_bf16:.2f} GB")
        print(f"  - FP32: {mem_fp32:.2f} GB")
        print("\nå®é™…è®­ç»ƒæ—¶ä¼°ç®— (AdamWä¼˜åŒ–å™¨ + æ¢¯åº¦):")
        print(f"  - FP16æ··åˆç²¾åº¦: {mem_fp16 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")
        print(f"  - FP32è®­ç»ƒ: {mem_fp32 * 4:.2f} GB  (å‚æ•°+æ¢¯åº¦+åŠ¨é‡+æ–¹å·®)")

        model_components.append(("Qwen-VL", params, mem_fp16, mem_fp32))

        print("\n" + "=" * 80 + "\n")

    except Exception as e:
        print(f"åŠ è½½ Qwen-VL æ¶æ„å¤±è´¥: {e}")

# æ‰“å°æ±‡æ€»ä¿¡æ¯
print("\n" + "=" * 60)
print("æ¨¡å‹æ¶æ„å®¡æŸ¥å®Œæˆ - æ˜¾å­˜å ç”¨æ€»ç»“")
print("=" * 60)

print(f"\næ€»å‚æ•°é‡: {total_params:,}")
print(f"  â‰ˆ {total_params / 1e6:.2f}M å‚æ•°")
print(f"  â‰ˆ {total_params / 1e9:.2f}B å‚æ•°")

# è®¡ç®—æ€»è®¡æ˜¾å­˜
total_fp16 = sum(mem[2] for mem in model_components)  # fp16æƒé‡
total_fp32 = sum(mem[3] for mem in model_components)  # fp32æƒé‡

print("\n" + "=" * 60)
print("æ˜¾å­˜å ç”¨ä¼°ç®—æ€»ç»“:")
print("=" * 60)

print("\nğŸ”µ æ¨ç†æ¨¡å¼ (ä»…åŠ è½½æƒé‡):")
print(f"  - FP16ç²¾åº¦: {total_fp16:.2f} GB")
print(f"  - BF16ç²¾åº¦: {total_fp16:.2f} GB")
print(f"  - FP32ç²¾åº¦: {total_fp32:.2f} GB")

print("\nğŸŸ¢ è®­ç»ƒæ¨¡å¼ (AdamWä¼˜åŒ–å™¨, éœ€è¦å­˜å‚¨æ¢¯åº¦+åŠ¨é‡+æ–¹å·®):")
print(f"  - FP16æ··åˆç²¾åº¦: {total_fp16 * 4:.2f} GB  (å‚æ•°Ã—4)")
print(f"  - FP32è®­ç»ƒ: {total_fp32 * 4:.2f} GB  (å‚æ•°Ã—4)")

print("\nâš ï¸  æ³¨æ„: ä»¥ä¸Šä¼°ç®—ä»…åŒ…å«æ¨¡å‹å‚æ•°æœ¬èº«ã€‚å®é™…ä½¿ç”¨æ—¶è¿˜éœ€è¦è€ƒè™‘:")
print("  - æ¿€æ´»å€¼ (activations) çš„æ˜¾å­˜å ç”¨")
print("  - è¾“å…¥/è¾“å‡ºå¼ é‡çš„æ˜¾å­˜å ç”¨")
print("  - æ‰¹æ¬¡å¤§å° (batch size) çš„å½±å“")
print("  - æ¢¯åº¦æ£€æŸ¥ç‚¹ (gradient checkpointing) å¯å‡å°‘æ¿€æ´»å€¼å ç”¨")
print("  - CUDAä¸Šä¸‹æ–‡å’Œå…¶ä»–ç³»ç»Ÿå¼€é”€")

print("\nğŸ“Š å„ç»„ä»¶è¯¦ç»†ç»Ÿè®¡:")
for name, params, mem_fp16, mem_fp32 in model_components:
    print(f"  - {name}: {params / 1e9:.2f}B å‚æ•°, FP16: {mem_fp16:.2f}GB, FP32: {mem_fp32:.2f}GB")

print(f"\nâœ… æ¨¡å‹æ¶æ„å®¡æŸ¥å®Œæ¯•ã€‚æ€»è®¡ {total_params / 1e9:.2f}B å‚æ•°ã€‚")
print("   æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹æƒé‡ï¼Œæ˜¾å­˜å ç”¨ä¸º 0 MB (meta device)ã€‚")
print(f"   å¦‚æœåŠ è½½æƒé‡ï¼Œä¼°è®¡éœ€è¦:")
print(f"     - æ¨ç†: {total_fp16:.1f}-{total_fp32:.1f} GB æ˜¾å­˜")
print(f"     - è®­ç»ƒ: {total_fp16 * 4:.1f}-{total_fp32 * 4:.1f} GB æ˜¾å­˜")